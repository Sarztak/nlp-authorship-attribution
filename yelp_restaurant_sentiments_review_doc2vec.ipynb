{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1PbbwuQuw1f6fraWhPEANFZbVT1CVtvSj",
      "authorship_tag": "ABX9TyOwKwL1ZEYE0cQiMhtYJUKS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sarztak/nlp-authorship-attribution/blob/main/yelp_restaurant_sentiments_review_doc2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "47N01YvL791g"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences, skipgrams, make_sampling_table\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding, Input, Flatten, Dense\n",
        "from tensorflow.keras import Sequential\n",
        "from rich.traceback import install\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "from nltk.util import ngrams\n",
        "import tensorflow as tf\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "install()\n",
        "drive_path = Path('/content/drive/MyDrive/yelp-restaurant-reviews-sentiments')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_size = 2000\n",
        "df = pd.read_csv(drive_path / \"train.csv\").sample(sample_size, random_state=1984).copy()"
      ],
      "metadata": {
        "id": "p6gnC_fH9I12"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = df.text.values, df.label.values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=1984)"
      ],
      "metadata": {
        "id": "uKRJ8efq9GT6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 5000 # limit the vocabulary to the 5000 most common words\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "tokenizer.fit_on_texts(X_test)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "KPtXKFgd9EZz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSReYUIATjqm",
        "outputId": "b8f80cf2-66c5-441f-e057-dd5d88880350"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15171"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngram_size = 2\n",
        "contexts, docids, targets = [], [], []\n",
        "for docid, s in enumerate(X_train_seq):\n",
        "    docids.append(docid)\n",
        "    ngram_list = list(ngrams(X_train_seq[docid], ngram_size))\n",
        "    for i in range(len(ngram_list) - 1):\n",
        "        contexts.append([docid, *ngram_list[i]])\n",
        "        targets.append(ngram_list[i + 1][-1])"
      ],
      "metadata": {
        "id": "wLnkYpOv_xHp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contexts[:4], targets[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcpSx2Ls93-6",
        "outputId": "90048158-a17b-4140-be49-2c8766d15086"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[0, 149, 16], [0, 16, 31], [0, 31, 86], [0, 86, 50]], [31, 86, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(contexts), len(docids), len(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArCKTm3r_lvS",
        "outputId": "4ef73aef-0cd0-46d9-edc2-89b7b86ba17e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178620, 1400, 178620)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min(targets), max(targets), vocab_size, len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfJTUN2dOOK8",
        "outputId": "8541f142-05e7-40bf-ecde-3d7521f59186"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 4999, 5000, 15171)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets = tf.one_hot(targets, depth=vocab_size + 1)"
      ],
      "metadata": {
        "id": "dteZ9fq3Q0G6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 1024\n",
        "BUFFER_SIZE = 10000\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "dataset = tf.data.Dataset.from_tensor_slices((contexts, targets))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8n7Y8Qt1HCUg",
        "outputId": "89071642-0a57-4d4c-a92b-11b53eac4c10"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_BatchDataset element_spec=(TensorSpec(shape=(1024, 3), dtype=tf.int32, name=None), TensorSpec(shape=(1024, 5001), dtype=tf.float32, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Doc2Vec(tf.keras.Model):\n",
        "  def __init__(self, doc_size, vocab_size, embedding_dim):\n",
        "    super().__init__()\n",
        "    self.doc_embedding = Embedding(doc_size,\n",
        "                                    embedding_dim,\n",
        "                                    name=\"doc_embedding\")\n",
        "    self.context_embedding = Embedding(vocab_size,\n",
        "                                       embedding_dim,\n",
        "                                       name=\"vec_embedding\")\n",
        "    self.flatten = Flatten()\n",
        "    self.dense = Dense(vocab_size)\n",
        "\n",
        "  def call(self, x):\n",
        "    docid = tf.reshape(x[:, 0], (x.shape[0], 1))\n",
        "    _context = x[:, 1:]\n",
        "    doc_emb = self.doc_embedding(docid) # (b, 1, emb_dim)\n",
        "    context_emb = self.context_embedding(_context) # (b, ngram_size, emb_dim)\n",
        "    input = tf.concat([doc_emb, context_emb], axis=1)\n",
        "    y = self.flatten(input)\n",
        "    y = self.dense(y)\n",
        "    return y"
      ],
      "metadata": {
        "id": "WF2cM4zRINOr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "doc_size = len(docids)\n",
        "doc2vec = Doc2Vec(doc_size, vocab_size + 1, embedding_dim)\n",
        "doc2vec.compile(optimizer=\"adam\", loss=CategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
        "doc2vec.fit(dataset, epochs=60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfty0NUrUiub",
        "outputId": "4cc42423-e358-4eca-dc16-5e71d73c3aac"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.0526 - loss: 7.9542\n",
            "Epoch 2/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.0932 - loss: 6.0149\n",
            "Epoch 3/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.1171 - loss: 5.5975\n",
            "Epoch 4/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.1359 - loss: 5.3326\n",
            "Epoch 5/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.1487 - loss: 5.1102\n",
            "Epoch 6/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.1628 - loss: 4.8930\n",
            "Epoch 7/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.1747 - loss: 4.6931\n",
            "Epoch 8/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.1877 - loss: 4.4944\n",
            "Epoch 9/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.2002 - loss: 4.3046\n",
            "Epoch 10/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.2138 - loss: 4.1197\n",
            "Epoch 11/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.2273 - loss: 3.9500\n",
            "Epoch 12/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.2407 - loss: 3.7931\n",
            "Epoch 13/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.2555 - loss: 3.6463\n",
            "Epoch 14/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.2713 - loss: 3.5084\n",
            "Epoch 15/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.2853 - loss: 3.3828\n",
            "Epoch 16/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.3009 - loss: 3.2676\n",
            "Epoch 17/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.3156 - loss: 3.1592\n",
            "Epoch 18/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.3306 - loss: 3.0564\n",
            "Epoch 19/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.3437 - loss: 2.9646\n",
            "Epoch 20/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.3567 - loss: 2.8808\n",
            "Epoch 21/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.3695 - loss: 2.7975\n",
            "Epoch 22/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.3824 - loss: 2.7225\n",
            "Epoch 23/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.3937 - loss: 2.6514\n",
            "Epoch 24/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4062 - loss: 2.5852\n",
            "Epoch 25/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.4165 - loss: 2.5238\n",
            "Epoch 26/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.4278 - loss: 2.4616\n",
            "Epoch 27/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.4377 - loss: 2.4095\n",
            "Epoch 28/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.4478 - loss: 2.3558\n",
            "Epoch 29/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.4572 - loss: 2.3049\n",
            "Epoch 30/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4651 - loss: 2.2595\n",
            "Epoch 31/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.4744 - loss: 2.2141\n",
            "Epoch 32/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4812 - loss: 2.1740\n",
            "Epoch 33/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.4886 - loss: 2.1352\n",
            "Epoch 34/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.4966 - loss: 2.0981\n",
            "Epoch 35/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.5022 - loss: 2.0622\n",
            "Epoch 36/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5096 - loss: 2.0287\n",
            "Epoch 37/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.5156 - loss: 1.9952\n",
            "Epoch 38/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.5205 - loss: 1.9658\n",
            "Epoch 39/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.5262 - loss: 1.9368\n",
            "Epoch 40/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.5318 - loss: 1.9091\n",
            "Epoch 41/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.5373 - loss: 1.8818\n",
            "Epoch 42/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.5417 - loss: 1.8563\n",
            "Epoch 43/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.5467 - loss: 1.8338\n",
            "Epoch 44/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.5521 - loss: 1.8095\n",
            "Epoch 45/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.5565 - loss: 1.7873\n",
            "Epoch 46/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.5600 - loss: 1.7679\n",
            "Epoch 47/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.5626 - loss: 1.7489\n",
            "Epoch 48/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.5664 - loss: 1.7300\n",
            "Epoch 49/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.5702 - loss: 1.7113\n",
            "Epoch 50/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5740 - loss: 1.6924\n",
            "Epoch 51/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.5766 - loss: 1.6757\n",
            "Epoch 52/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.5799 - loss: 1.6589\n",
            "Epoch 53/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.5827 - loss: 1.6433\n",
            "Epoch 54/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5860 - loss: 1.6282\n",
            "Epoch 55/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.5892 - loss: 1.6112\n",
            "Epoch 56/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.5912 - loss: 1.5979\n",
            "Epoch 57/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5939 - loss: 1.5859\n",
            "Epoch 58/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.5969 - loss: 1.5719\n",
            "Epoch 59/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.5990 - loss: 1.5618\n",
            "Epoch 60/60\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.6013 - loss: 1.5480\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cdcac9ac5c0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}